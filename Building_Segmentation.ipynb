{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frJUqimE4zll"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/qubvel/segmentation_models.pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Nylk7Dzo5AEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '${dataset_root}/png'\n",
        "\n",
        "# Define directories for training, validation, and testing data\n",
        "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train_labels')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'val_labels')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test_labels')\n",
        "\n",
        "# Define class names, class indices, and RGB values for each class\n",
        "class_names = ['background', 'building']    # select_classes\n",
        "class_idx = [0,1]                           # select_class_indices\n",
        "class_rgb_values = [[0,0,0], [255,255,255]] # select_class_rgb_values"
      ],
      "metadata": {
        "id": "ne0T96xe5AHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample image and its corresponding mask for visualization\n",
        "x_sample = cv2.imread(os.path.join(x_train_dir, os.listdir(x_train_dir)[0]))\n",
        "y_sample = cv2.imread(os.path.join(y_train_dir, os.listdir(y_train_dir)[0]))\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('RGB Image')\n",
        "plt.imshow(cv2.cvtColor(x_sample, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Mask')\n",
        "plt.imshow(cv2.cvtColor(y_sample, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "whi4IOUjHSXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cADdVr70HUnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import segmentation_models_pytorch.utils as su"
      ],
      "metadata": {
        "id": "wokCAKCD5ALY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(**images):\n",
        "    n_images = len(images)\n",
        "    plt.figure(figsize=(20,8))\n",
        "    for idx, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n_images, idx + 1)\n",
        "        plt.xticks([]);\n",
        "        plt.yticks([])\n",
        "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# Define a function to convert ground truth masks to one-hot encoded format\n",
        "def one_hot_encode(label, label_values):\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(label, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)\n",
        "\n",
        "    return semantic_map\n",
        "# Define a function to convert one-hot encoded masks back to RGB format\n",
        "def reverse_one_hot(image):\n",
        "    x = np.argmax(image, axis = -1)\n",
        "    return x\n",
        "\n",
        "# Define a function to color-code segmentation masks\n",
        "def colour_code_segmentation(image, label_values):\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[image.astype(int)]\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "2CHnadnb5ANs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class for the dataset\n",
        "class BuildingsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            images_dir, # Directory containing the images\n",
        "            masks_dir, # Directory containing the corresponding masks\n",
        "            class_rgb_values=None, # RGB values for each class for one-hot encoding\n",
        "            augmentation=None, # Augmentation transformations to be applied\n",
        "            preprocessing=None, # Preprocessing transformations to be applied\n",
        "    ):\n",
        "\n",
        "        # Store the paths to images and masks\n",
        "        self.image_paths = [os.path.join(images_dir, image_id) for image_id in sorted(os.listdir(images_dir))]\n",
        "        self.mask_paths = [os.path.join(masks_dir, image_id) for image_id in sorted(os.listdir(masks_dir))]\n",
        "\n",
        "        self.class_rgb_values = class_rgb_values\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        # Load the image and mask at index i\n",
        "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Perform one-hot encoding on the mask using class RGB values\n",
        "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
        "\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)"
      ],
      "metadata": {
        "id": "705GxI6N5APx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation transformations\n",
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "        album.RandomCrop(height=256, width=256, always_apply=True),\n",
        "        album.OneOf(\n",
        "            [\n",
        "                album.HorizontalFlip(p=1),\n",
        "                album.VerticalFlip(p=1),\n",
        "                album.RandomRotate90(p=1),\n",
        "            ],\n",
        "            p=0.75,\n",
        "        ),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "# Define validation augmentation transformations\n",
        "def get_validation_augmentation():\n",
        "    # Add sufficient padding to ensure image is divisible by 32\n",
        "    test_transform = [\n",
        "        album.PadIfNeeded(min_height=1536, min_width=1536, always_apply=True, border_mode=0),\n",
        "    ]\n",
        "    return album.Compose(test_transform)\n",
        "\n",
        "# Define preprocessing transformations\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn=None):\n",
        "    _transform = []\n",
        "    if preprocessing_fn:\n",
        "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
        "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
        "\n",
        "    return album.Compose(_transform)"
      ],
      "metadata": {
        "id": "_9jRYnTT5ARt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for model training and evaluation\n",
        "DATA_DIR = '${dataset_root}/png'\n",
        "SAVE_WEIGHT = 'path to save model weights '\n",
        "\n",
        "ENCODER = 'resnet101'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = class_names\n",
        "ACTIVATION = 'sigmoid'\n",
        "\n",
        "TRAINING = True\n",
        "EPOCHS = 80\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "PRETRAING_WEIGHT_PATH = None"
      ],
      "metadata": {
        "id": "__FIyq7q5ATz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train_labels')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'val_labels')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test_labels')\n",
        "\n",
        "class_names = ['background', 'building']\n",
        "class_idx = [0,1]\n",
        "class_rgb_values = [[0,0,0], [255,255,255]]"
      ],
      "metadata": {
        "id": "GvDRlUSF5AV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = BuildingsDataset(x_train_dir, y_train_dir, class_rgb_values=class_rgb_values)\n",
        "augmented_dataset = BuildingsDataset(\n",
        "    x_train_dir, y_train_dir,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    class_rgb_values=class_rgb_values,\n",
        ")"
      ],
      "metadata": {
        "id": "2xrddWVT5AX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = smp.DeepLabV3Plus(encoder_name=ENCODER,encoder_weights=ENCODER_WEIGHTS,classes=len(CLASSES),activation=ACTIVATION)\n",
        "# Get preprocessing function based on the selected encoder\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
        "# Load pre-trained weights if specified and the file exists\n",
        "if PRETRAING_WEIGHT_PATH is not None and os.path.exists(PRETRAING_WEIGHT_PATH):\n",
        "    model = torch.load('m_buildings/deeplabv3-efficientnetb4-frontend-using-pytorch/best_model.pth', map_location=DEVICE)"
      ],
      "metadata": {
        "id": "mMDfbseM5AZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation datasets with augmentation and preprocessing\n",
        "train_dataset = BuildingsDataset(\n",
        "    x_train_dir, y_train_dir,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=class_rgb_values,\n",
        ")\n",
        "valid_dataset = BuildingsDataset(\n",
        "    x_valid_dir, y_valid_dir,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values= class_rgb_values,\n",
        ")\n",
        "# Create data loaders for training and validation datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "_RLxXI-g5Ab_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss, metrics, optimizer, and learning rate scheduler\n",
        "loss = su.losses.DiceLoss()\n",
        "metrics = [su.metrics.IoU(threshold=0.5),]\n",
        "optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.0001),])\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2, eta_min=5e-5,)"
      ],
      "metadata": {
        "id": "hNF4mWAn5Ad-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation epochs\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "zr1ENJgk5Af_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model if TRAINING is True\n",
        "%%time\n",
        "if TRAINING:\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "    for i in range(0, EPOCHS):\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "        file_name = f'model_epoch_{i:03d}.pth'\n",
        "        torch.save(model, os.path.join(SAVE_WEIGHT, file_name))\n",
        "\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            file_name = f'best_model.pth'\n",
        "            torch.save(model, os.path.join(SAVE_WEIGHT, file_name))\n",
        "        print('Best Model Update!')"
      ],
      "metadata": {
        "id": "r2hZ5aaV5AiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iWud5yEBHZ9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import segmentation_models_pytorch.utils as su"
      ],
      "metadata": {
        "id": "GXSPv6965Akg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '${dataset_root}/png'\n",
        "SAVE_WEIGHT = 'path to save model weights'\n",
        "WEIGHT_FILE_NAME = 'weight file path'\n",
        "\n",
        "ENCODER = 'resnet101'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = class_names\n",
        "ACTIVATION = 'sigmoid'\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test_labels')\n",
        "\n",
        "class_names = ['background', 'building']\n",
        "class_idx = [0,1]\n",
        "class_rgb_values = [[0,0,0], [255,255,255]]"
      ],
      "metadata": {
        "id": "QM08E-lX5Amo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.DeepLabV3Plus(encoder_name=ENCODER,encoder_weights=ENCODER_WEIGHTS,classes=len(CLASSES),activation=ACTIVATION)\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
        "if os.path.exists(os.path.join(SAVE_WEIGHT, WEIGHT_FILE_NAME)):\n",
        "    best_model = torch.load(os.path.join(SAVE_WEIGHT, WEIGHT_FILE_NAME), map_location=DEVICE)\n",
        "    print('Loaded DeepLabV3+ model from this run.')"
      ],
      "metadata": {
        "id": "ITrvN70D5Aoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = BuildingsDataset(\n",
        "    x_test_dir,\n",
        "    y_test_dir,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset)"
      ],
      "metadata": {
        "id": "q9o8DHf15Aq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_epoch = su.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")"
      ],
      "metadata": {
        "id": "iN1FyKmo5As6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IDpyITDDHbLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import segmentation_models_pytorch.utils as su"
      ],
      "metadata": {
        "id": "jBLc4sks5AvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '${dataset_root}/png'\n",
        "SAVE_WEIGHT = 'path to save model weights'\n",
        "WEIGHT_FILE_NAME = 'weight file path'\n",
        "\n",
        "ENCODER = 'resnet101'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = class_names\n",
        "ACTIVATION = 'sigmoid'\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test_labels')\n",
        "\n",
        "class_names = ['background', 'building']\n",
        "class_idx = [0,1]\n",
        "class_rgb_values = [[0,0,0], [255,255,255]]"
      ],
      "metadata": {
        "id": "w8RwR2ti5AxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.DeepLabV3Plus(encoder_name=ENCODER,encoder_weights=ENCODER_WEIGHTS,classes=len(CLASSES),activation=ACTIVATION)\n",
        "if os.path.exists(os.path.join(SAVE_WEIGHT, WEIGHT_FILE_NAME)):\n",
        "    model = torch.load(os.path.join(SAVE_WEIGHT, WEIGHT_FILE_NAME), map_location=DEVICE)\n",
        "    print('Loaded DeepLabV3+ model from this run.')"
      ],
      "metadata": {
        "id": "oYnhM0Q95A1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_preds_folder = ' path to folder for test resluts'\n",
        "if not os.path.exists(sample_preds_folder):\n",
        "    os.makedirs(sample_preds_folder)"
      ],
      "metadata": {
        "id": "zK_4FGao5A3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Center crop padded image / mask to original image dims\n",
        "def crop_image(image, target_image_dims=[1500,1500,3]):\n",
        "\n",
        "    target_size = target_image_dims[0]\n",
        "    image_size = len(image)\n",
        "    padding = (image_size - target_size) // 2\n",
        "\n",
        "    return image[\n",
        "        padding:image_size - padding,\n",
        "        padding:image_size - padding,\n",
        "        :,\n",
        "    ]"
      ],
      "metadata": {
        "id": "fyhfinwD9VP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_vis = BuildingsDataset(\n",
        "    x_test_dir, y_test_dir,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    class_rgb_values=class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataset = BuildingsDataset(\n",
        "    x_test_dir,\n",
        "    y_test_dir,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=class_rgb_values,\n",
        ")"
      ],
      "metadata": {
        "id": "qItJaJpA9VSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(test_dataset)):\n",
        "    image, gt_mask = test_dataset[idx]\n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "    pred_mask = model(x_tensor)\n",
        "\n",
        "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "    pred_building_heatmap = pred_mask[:,:,class_names.index('building')]\n",
        "    pred_mask = crop_image(colour_code_segmentation(reverse_one_hot(pred_mask), class_rgb_values))\n",
        "    # Convert gt_mask from `CHW` format to `HWC` format\n",
        "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
        "    gt_mask = crop_image(colour_code_segmentation(reverse_one_hot(gt_mask), class_rgb_values))\n",
        "    image_vis = crop_image(test_dataset_vis[idx][0].astype('uint8'))\n",
        "\n",
        "    result = np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1]\n",
        "    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), result)\n",
        "\n",
        "    b,g,r = cv2.split(result)\n",
        "    result[:,:,0] = r\n",
        "    result[:,:,2] = b\n",
        "    plt.imshow(result)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tiAmTzGs9VUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_qgCFSEHc24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import albumentations as album\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import segmentation_models_pytorch as smp"
      ],
      "metadata": {
        "id": "uimbnEPg9VWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '${dataset_root}/png'\n",
        "SAVE_WEIGHT = 'path to save model weights'\n",
        "WEIGHT_FILE_NAME ='weight file path'\n",
        "\n",
        "ENCODER = 'resnet101'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = class_names\n",
        "ACTIVATION = 'sigmoid'\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class_names = ['background', 'building']\n",
        "class_idx = [0,1]\n",
        "class_rgb_values = [[0,0,0], [255,255,255]]"
      ],
      "metadata": {
        "id": "A_QdRg3n5A57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.DeepLabV3Plus(encoder_name=ENCODER,encoder_weights=ENCODER_WEIGHTS,classes=len(CLASSES),activation=ACTIVATION)\n",
        "if os.path.exists(os.path.join(SAVE_WEIGHT, WEIGHT_FILE_NAME)):\n",
        "    model = torch.load(os.path.join(SAVE_WEIGHT, WEIGHT_FILE_NAME), map_location=DEVICE)\n",
        "    print('Loaded DeepLabV3+ model from this run.')\n",
        "\n",
        "print('Model Loaded!')"
      ],
      "metadata": {
        "id": "e-8itYnL9cHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test_labels')"
      ],
      "metadata": {
        "id": "4WyPqGNc9cJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_validation_augmentation():\n",
        "    # Add sufficient padding to ensure image is divisible by 32\n",
        "    test_transform = [\n",
        "        album.PadIfNeeded(min_height=1536, min_width=1536, always_apply=True, border_mode=0),\n",
        "    ]\n",
        "    return album.Compose(test_transform)"
      ],
      "metadata": {
        "id": "RJuGl_I99cLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = cv2.imread(os.path.join(x_test_dir, os.listdir(x_test_dir)[0]))\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "augmentor = album.PadIfNeeded(min_height=1536, min_width=1536, always_apply=True, border_mode=0)\n",
        "input_image = augmentor(image=test_img)['image']\n",
        "input_image = preprocessing_fn(input_image)\n",
        "input_image = np.transpose(input_image,(2,0,1)).astype('float32')\n",
        "input_image = torch.from_numpy(input_image).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "pred_mask = model(input_image)\n",
        "pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "\n",
        "pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "\n",
        "pred_building_heatmap = pred_mask[:,:,class_names.index('building')]\n",
        "pred_mask = crop_image(colour_code_segmentation(reverse_one_hot(pred_mask), class_rgb_values)).astype('uint8')\n",
        "\n",
        "test_img_label = cv2.imread(os.path.join(y_test_dir, os.listdir(y_test_dir)[0]))\n",
        "test_img_label = crop_image(cv2.cvtColor(test_img_label, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Image\")\n",
        "plt.imshow(test_img)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(\"GT MASK\")\n",
        "plt.imshow(test_img_label)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"PRED MASK\")\n",
        "plt.imshow(pred_mask)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oTwmHeT49fl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}